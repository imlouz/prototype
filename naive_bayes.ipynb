{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordClassifier:\n",
    "\n",
    "    def get_features(self):\n",
    "        names = self._load_names()\n",
    "        transliterables = names['transliterable']\n",
    "        nontransliterables = names['nontransliterable']\n",
    "        featureset = list()\n",
    "\n",
    "        for trans in transliterables:\n",
    "            features = self._name_features(trans)\n",
    "            featureset.append((features, 'transliterable'))\n",
    "\n",
    "        for nontrans in nontransliterables:\n",
    "            features = self._name_features(nontrans)\n",
    "            featureset.append((features, 'nontransliterable'))\n",
    "\n",
    "        return featureset\n",
    "\n",
    "    def train_and_test(self, training_percent=0.90):\n",
    "        featureset = self.get_features()\n",
    "        print('[1] Саралов ...')\n",
    "        random.shuffle(featureset)\n",
    "\n",
    "        name_count = len(featureset)\n",
    "        cut_point = int(name_count * training_percent)\n",
    "\n",
    "        train_set = featureset[:cut_point]\n",
    "        test_set = featureset[cut_point:]\n",
    "\n",
    "        train_set = featureset\n",
    "        test_set = featureset\n",
    "\n",
    "        print('[2] Тайёрлов ...')\n",
    "        self.train(train_set)\n",
    "\n",
    "        print('[3] Якуний синов ...')\n",
    "        return self.test(test_set)\n",
    "\n",
    "    def classify(self, name):\n",
    "        feats = self._name_features(name)\n",
    "        return self.classifier.classify(feats)\n",
    "\n",
    "    def train(self, train_set):\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        return self.classifier\n",
    "\n",
    "    def test(self, test_set):\n",
    "        return nltk.classify.accuracy(self.classifier, test_set)\n",
    "\n",
    "    def _load_names(self):\n",
    "        names = dict()\n",
    "        names['transliterable'] = list()\n",
    "        names['nontransliterable'] = list()\n",
    "        with open('wordlist.csv') as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            for row in csvreader:\n",
    "                names[row[0]].append(row[1])\n",
    "\n",
    "        return names\n",
    "\n",
    "    def _get_prob_distr(self, name_tuple):\n",
    "        trans_prob = (name_tuple[1] * 1.0) / (name_tuple[1] + name_tuple[2])\n",
    "\n",
    "        if trans_prob == 1.0:\n",
    "            trans_prob = 0.99\n",
    "        elif trans_prob == 0.0:\n",
    "            trans_prob = 0.01\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        nontrans_prob = 1.0 - nontrans_prob\n",
    "        return (trans_prob, nontrans_prob)\n",
    "\n",
    "    def get_most_informative_features(self, n=5):\n",
    "        return self.classifier.most_informative_features(n)\n",
    "\n",
    "    def _name_features(self, name):\n",
    "        name = name.lower()\n",
    "        return {\n",
    "            'last_letter': name[-1],\n",
    "            'last_two': name[-2:],\n",
    "            'last_three': name[-3:],\n",
    "            'last_four': (lambda: name[-4:] if len(name) >= 4 else name)(),\n",
    "            'first_two': name[:2],\n",
    "            'first_three': name[:3],\n",
    "            'first_four': (lambda: name[:-4] if len(name) >= 4 else name)(),\n",
    "            'last_is_vowel': (name[-1] in 'aeiou')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Саралов ...\n",
      "[2] Тайёрлов ...\n",
      "[3] Якуний синов ...\n",
      "Аниқлик даражаси:  0.98\n"
     ]
    }
   ],
   "source": [
    "wc = WordClassifier()\n",
    "accuracy = wc.train_and_test()\n",
    "print('Аниқлик даражаси: ', round(accuracy, 2))\n",
    "\n",
    "_ = {\n",
    "    'transliterable': 'ўгирилиши керак',\n",
    "    'nontransliterable': 'ўгириш керак эмас'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"daryo.uz\" сўзини кириллчага ўгириш керак эмас\n"
     ]
    }
   ],
   "source": [
    "word = 'daryo.uz'\n",
    "decision = _[wc.classify(word)]\n",
    "\n",
    "print('\"{word}\" сўзини кириллчага {decision}'.format(word=word, decision=decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''\n",
    "Google yuqori tariflar bois Xitoydagi ishlab chiqarishlarini qisqartirmoqda\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Google\" сўзини кириллчага ўгириш керак эмас\n",
      "\"yuqori\" сўзини кириллчага ўгирилиши керак\n",
      "\"tariflar\" сўзини кириллчага ўгирилиши керак\n",
      "\"bois\" сўзини кириллчага ўгириш керак эмас\n",
      "\"Xitoydagi\" сўзини кириллчага ўгирилиши керак\n",
      "\"ishlab\" сўзини кириллчага ўгирилиши керак\n",
      "\"chiqarishlarini\" сўзини кириллчага ўгирилиши керак\n",
      "\"qisqartirmoqda\" сўзини кириллчага ўгирилиши керак\n"
     ]
    }
   ],
   "source": [
    "for word in sentence.split():\n",
    "    decision = _[wc.classify(word.lower())]\n",
    "    print('\"{word}\" сўзини кириллчага {decision}'.format(word=word, decision=decision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
