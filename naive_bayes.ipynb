{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordClassifier:\n",
    "\n",
    "    def get_features(self):\n",
    "        words = self._load_words()\n",
    "        transliterables = words['transliterable']\n",
    "        nontransliterables = words['nontransliterable']\n",
    "        featureset = list()\n",
    "\n",
    "        for trans in transliterables:\n",
    "            features = self._word_features(trans)\n",
    "            featureset.append((features, 'transliterable'))\n",
    "\n",
    "        for nontrans in nontransliterables:\n",
    "            features = self._word_features(nontrans)\n",
    "            featureset.append((features, 'nontransliterable'))\n",
    "\n",
    "        return featureset\n",
    "\n",
    "    def train_and_test(self, training_percent=0.90):\n",
    "        featureset = self.get_features()\n",
    "        print('[1] Саралов ...')\n",
    "        random.shuffle(featureset)\n",
    "\n",
    "        word_count = len(featureset)\n",
    "        cut_point = int(word_count * training_percent)\n",
    "\n",
    "        train_set = featureset[:cut_point]\n",
    "        test_set = featureset[cut_point:]\n",
    "\n",
    "        train_set = featureset\n",
    "        test_set = featureset\n",
    "\n",
    "        print('[2] Тайёрлов ...')\n",
    "        self.train(train_set)\n",
    "\n",
    "        print('[3] Якуний синов ...')\n",
    "        return self.test(test_set)\n",
    "\n",
    "    def classify(self, word):\n",
    "        feats = self._word_features(word)\n",
    "        return self.classifier.classify(feats)\n",
    "\n",
    "    def train(self, train_set):\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        return self.classifier\n",
    "\n",
    "    def test(self, test_set):\n",
    "        return nltk.classify.accuracy(self.classifier, test_set)\n",
    "\n",
    "    def _load_words(self):\n",
    "        words = dict()\n",
    "        words['transliterable'] = list()\n",
    "        words['nontransliterable'] = list()\n",
    "        with open('wordlist.csv') as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            for row in csvreader:\n",
    "                words[row[0]].append(row[1])\n",
    "\n",
    "        return words\n",
    "\n",
    "    def _get_prob_distr(self, word_tuple):\n",
    "        trans_prob = (word_tuple[1] * 1.0) / (word_tuple[1] + word_tuple[2])\n",
    "\n",
    "        if trans_prob == 1.0:\n",
    "            trans_prob = 0.99\n",
    "        elif trans_prob == 0.0:\n",
    "            trans_prob = 0.01\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        nontrans_prob = 1.0 - nontrans_prob\n",
    "        return (trans_prob, nontrans_prob)\n",
    "\n",
    "    def get_most_informative_features(self, n=5):\n",
    "        return self.classifier.most_informative_features(n)\n",
    "\n",
    "    def _word_features(self, word):\n",
    "        word = word.lower()\n",
    "        return {\n",
    "            'last_letter': word[-1],\n",
    "            'last_two': word[-2:],\n",
    "            'last_three': word[-3:],\n",
    "            'last_four': (lambda: word[-4:] if len(word) >= 4 else word)(),\n",
    "            'first_two': word[:2],\n",
    "            'first_three': word[:3],\n",
    "            'first_four': (lambda: word[:-4] if len(word) >= 4 else word)(),\n",
    "            'last_is_vowel': (word[-1] in 'aeiou')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Саралов ...\n",
      "[2] Тайёрлов ...\n",
      "[3] Якуний синов ...\n",
      "Аниқлик даражаси:  0.9825\n"
     ]
    }
   ],
   "source": [
    "wc = WordClassifier()\n",
    "accuracy = wc.train_and_test()\n",
    "print('Аниқлик даражаси: ', round(accuracy, 4))\n",
    "\n",
    "_ = {\n",
    "    'transliterable': 'ўгирилиши шарт',\n",
    "    'nontransliterable': 'ўгирилиши шартмас'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"daryo.uz\" сўзи кириллчага ўгирилиши шартмас\n"
     ]
    }
   ],
   "source": [
    "word = 'daryo.uz'\n",
    "decision = _[wc.classify(word)]\n",
    "\n",
    "print('\"{word}\" сўзи кириллчага {decision}'.format(word=word, decision=decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''\n",
    "Google yuqori tariflar bois Xitoydagi ishlab chiqarishlarini qisqartirmoqda. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"google\" сўзини кириллчага ўгирилиши шартмас\n",
      "\"yuqori\" сўзини кириллчага ўгирилиши шарт\n",
      "\"tariflar\" сўзини кириллчага ўгирилиши шарт\n",
      "\"bois\" сўзини кириллчага ўгирилиши шартмас\n",
      "\"xitoydagi\" сўзини кириллчага ўгирилиши шарт\n",
      "\"ishlab\" сўзини кириллчага ўгирилиши шарт\n",
      "\"chiqarishlarini\" сўзини кириллчага ўгирилиши шарт\n",
      "\"qisqartirmoqda\" сўзини кириллчага ўгирилиши шарт\n"
     ]
    }
   ],
   "source": [
    "sentence = sentence.replace(',', ' ').replace('.', ' ')\n",
    "for word in sentence.split():\n",
    "    word = word.lower()\n",
    "    decision = _[wc.classify(word)]\n",
    "    print('\"{word}\" сўзини кириллчага {decision}'.format(word=word, decision=decision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
